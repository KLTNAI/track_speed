{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bytetrack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- CẤU HÌNH ---\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "video_path = os.path.join('.', 'data', 'car.mp4') # Đổi tên video của bạn\n",
    "model_path = \"yolo11n.pt\"  # Dùng Nano hoặc Small\n",
    "\n",
    "# Tọa độ vạch đếm \n",
    "LINE_START = (200, 500) \n",
    "LINE_END = (1100, 500)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Biến lưu trữ đếm\n",
    "total_count_up = 0\n",
    "total_count_down = 0\n",
    "previous_positions = {} # Lưu vị trí cũ: {track_id: (cx, cy)}\n",
    "\n",
    "# HÀM KIỂM TRA CẮT VẠCH (Giữ nguyên logic cũ)\n",
    "def ccw(A, B, C):\n",
    "    return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])\n",
    "\n",
    "def intersect(A, B, C, D):\n",
    "    return ccw(A,C,D) != ccw(B,C,D) and ccw(A,B,C) != ccw(A,B,D)\n",
    "\n",
    "cv2.namedWindow('ByteTrack Counter', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('ByteTrack Counter', 1280, 720)\n",
    "\n",
    "print(\"Đang chạy ByteTrack... Nhanh và chính xác hơn DeepSort.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # conf=0.25: Để thấp một chút để ByteTrack tự xử lý các xe ở xa\n",
    "    results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\", \n",
    "                          classes=[2, 3, 5, 7], conf=0.25, verbose=False)\n",
    "\n",
    "    # Vẽ vạch\n",
    "    cv2.line(frame, LINE_START, LINE_END, (255, 0, 0), 3)\n",
    "\n",
    "    # Lấy kết quả từ YOLO\n",
    "    if results[0].boxes.id is not None:\n",
    "        # Lấy các thông số: boxes (x,y,x,y), ids, class_ids\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "        track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "        class_ids = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "        \n",
    "        # Duyệt qua từng xe\n",
    "        for box, track_id, class_id in zip(boxes, track_ids, class_ids):\n",
    "            x1, y1, x2, y2 = box\n",
    "            \n",
    "            # Tính tâm hiện tại\n",
    "            cx = (x1 + x2) // 2\n",
    "            cy = (y1 + y2) // 2\n",
    "            current_center = (cx, cy)\n",
    "\n",
    "            # LOGIC ĐẾM XE \n",
    "            if track_id in previous_positions:\n",
    "                prev_center = previous_positions[track_id]\n",
    "\n",
    "                if intersect(prev_center, current_center, LINE_START, LINE_END):\n",
    "                    if current_center[1] < prev_center[1]: \n",
    "                        total_count_up += 1\n",
    "                    else:\n",
    "                        total_count_down += 1\n",
    "                    \n",
    "                    cv2.line(frame, LINE_START, LINE_END, (0, 255, 0), 5)\n",
    "                    print(f\"Xe #{track_id} cắt vạch!\")\n",
    "\n",
    "            previous_positions[track_id] = current_center\n",
    "            \n",
    "\n",
    "            # Vẽ hình\n",
    "            label = f\"#{track_id} {model.names[class_id]}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            cv2.circle(frame, current_center, 4, (0, 0, 255), -1)\n",
    "\n",
    "    # Hiển thị bảng kết quả\n",
    "    cv2.rectangle(frame, (20, 20), (250, 100), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Len: {total_count_up}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"Xuong: {total_count_down}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('ByteTrack Counter', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bytetrack + count + speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "VIDEO_PATH = r\"E:\\Study\\deeplearning\\final\\supervision\\examples\\speed_estimation\\data\\car.mp4\"\n",
    "MODEL_PATH = \"yolo11n.pt\"  # Dùng Nano cho mượt, máy khỏe thì đổi thành \"yolo11s.pt\"\n",
    "\n",
    "# TỌA ĐỘ VÙNG CHỌN (QUAN TRỌNG NHẤT)\n",
    "# Dùng tool get_points.py để lấy 4 điểm này trên video CỦA BẠN.\n",
    "# Thứ tự: [Góc trên-trái, Góc trên-phải, Góc dưới-phải, Góc dưới-trái]\n",
    "SOURCE = np.array([\n",
    "    [1252, 787], \n",
    "    [2298, 803], \n",
    "    [5039, 2159], \n",
    "    [-550, 2159]\n",
    "])\n",
    "\n",
    "# Kích thước thực tế ngoài đời của vùng chọn (đơn vị: mét)\n",
    "# Ví dụ: Đoạn đường đó dài 250m, rộng 25m\n",
    "TARGET_WIDTH = 25\n",
    "TARGET_HEIGHT = 250\n",
    "\n",
    "TARGET = np.array([\n",
    "    [0, 0],\n",
    "    [TARGET_WIDTH - 1, 0],\n",
    "    [TARGET_WIDTH - 1, TARGET_HEIGHT - 1],\n",
    "    [0, TARGET_HEIGHT - 1],\n",
    "])\n",
    "\n",
    "\n",
    "class ViewTransformer:\n",
    "    def __init__(self, source: np.ndarray, target: np.ndarray) -> None:\n",
    "        source = source.astype(np.float32)\n",
    "        target = target.astype(np.float32)\n",
    "        self.m = cv2.getPerspectiveTransform(source, target)\n",
    "\n",
    "    def transform_points(self, points: np.ndarray) -> np.ndarray:\n",
    "        if points.size == 0:\n",
    "            return points\n",
    "        reshaped_points = points.reshape(-1, 1, 2).astype(np.float32)\n",
    "        transformed_points = cv2.perspectiveTransform(reshaped_points, self.m)\n",
    "        return transformed_points.reshape(-1, 2)\n",
    "\n",
    "def main():\n",
    "    # 1. Khởi tạo Model và Video Info\n",
    "    video_info = sv.VideoInfo.from_video_path(video_path=VIDEO_PATH)\n",
    "    model = YOLO(MODEL_PATH)\n",
    "\n",
    "    # 2. Khởi tạo ByteTrack (Đã có sẵn trong supervision)\n",
    "    # track_activation_threshold=0.25: Giúp bắt xe ở xa/mờ tốt hơn\n",
    "    byte_track = sv.ByteTrack(frame_rate=video_info.fps, track_activation_threshold=0.25)\n",
    "\n",
    "    # 3. Các công cụ vẽ (Annotators)\n",
    "    thickness = sv.calculate_optimal_line_thickness(resolution_wh=video_info.resolution_wh)\n",
    "    text_scale = sv.calculate_optimal_text_scale(resolution_wh=video_info.resolution_wh)\n",
    "    \n",
    "    box_annotator = sv.BoxAnnotator(thickness=thickness)\n",
    "    label_annotator = sv.LabelAnnotator(\n",
    "        text_scale=text_scale, \n",
    "        text_thickness=thickness, \n",
    "        text_position=sv.Position.BOTTOM_CENTER\n",
    "    )\n",
    "    trace_annotator = sv.TraceAnnotator(\n",
    "        thickness=thickness, \n",
    "        trace_length=video_info.fps * 2, \n",
    "        position=sv.Position.BOTTOM_CENTER\n",
    "    )\n",
    "\n",
    "    # 4. Công cụ tính toán tốc độ\n",
    "    frame_generator = sv.get_video_frames_generator(source_path=VIDEO_PATH)\n",
    "    polygon_zone = sv.PolygonZone(polygon=SOURCE)\n",
    "    view_transformer = ViewTransformer(source=SOURCE, target=TARGET)\n",
    "    \n",
    "    # Lưu trữ tọa độ để tính vận tốc\n",
    "    coordinates = defaultdict(lambda: deque(maxlen=video_info.fps))\n",
    "\n",
    "    # Cài đặt cửa sổ hiển thị\n",
    "    cv2.namedWindow('ByteTrack', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('ByteTrack', 1280, 720)\n",
    "\n",
    "    print(\"Đang chạy... Nhấn 'q' để thoát.\")\n",
    "\n",
    "    # 5. Vòng lặp chính\n",
    "    for frame in frame_generator:\n",
    "        # Nhận diện YOLO\n",
    "        result = model(frame, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "\n",
    "        # Lọc kết quả\n",
    "        detections = detections[detections.confidence > 0.3] # Chỉ lấy độ tin cậy > 0.3\n",
    "        \n",
    "        # Chỉ xử lý xe nằm trong vùng SOURCE (Polygon)\n",
    "        # Nếu muốn đo cả xe ngoài vùng thì bỏ dòng này đi\n",
    "        detections = detections[polygon_zone.trigger(detections)] \n",
    "        \n",
    "        detections = detections.with_nms(threshold=0.7)\n",
    "        \n",
    "        # CẬP NHẬT TRACKER (BYTETRACK)\n",
    "        detections = byte_track.update_with_detections(detections=detections)\n",
    "\n",
    "        # TÍNH TOÁN TỐC ĐỘ \n",
    "        points = detections.get_anchors_coordinates(anchor=sv.Position.BOTTOM_CENTER)\n",
    "        points = view_transformer.transform_points(points=points).astype(int)\n",
    "\n",
    "        for tracker_id, [_, y] in zip(detections.tracker_id, points):\n",
    "            coordinates[tracker_id].append(y)\n",
    "\n",
    "        labels = []\n",
    "        for tracker_id, class_id in zip(detections.tracker_id, detections.class_id):\n",
    "            class_name = model.names[class_id] # Lấy tên xe (car, bus...)\n",
    "            \n",
    "            if len(coordinates[tracker_id]) < video_info.fps / 2:\n",
    "                labels.append(f\"#{tracker_id} {class_name}\")\n",
    "            else:\n",
    "                # Công thức tính vận tốc: v = s / t\n",
    "                coordinate_start = coordinates[tracker_id][-1]\n",
    "                coordinate_end = coordinates[tracker_id][0]\n",
    "                distance = abs(coordinate_start - coordinate_end)\n",
    "                time = len(coordinates[tracker_id]) / video_info.fps\n",
    "                speed = distance / time * 3.6 # Đổi m/s sang km/h\n",
    "                \n",
    "                labels.append(f\"#{tracker_id} {class_name} {int(speed)} km/h\")\n",
    "\n",
    "        \n",
    "        annotated_frame = frame.copy()\n",
    "        \n",
    "        # Vẽ vùng chọn SOURCE để căn chỉnh\n",
    "        cv2.polylines(annotated_frame, [SOURCE.astype(np.int32)], True, (0, 0, 255), 2)\n",
    "\n",
    "        annotated_frame = trace_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "        annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "        # Hiển thị\n",
    "        cv2.imshow(\"Do an Tot Nghiep - ByteTrack\", annotated_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speed trâu bò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict, deque\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import torch\n",
    "\n",
    "\n",
    "# 1. Tọa độ vùng chọn \n",
    "SOURCE = np.array([\n",
    "    [1252, 787], \n",
    "    [2298, 803], \n",
    "    [5039, 2159], \n",
    "    [-550, 2159]\n",
    "])\n",
    "\n",
    "TARGET_WIDTH = 25\n",
    "TARGET_HEIGHT = 250\n",
    "\n",
    "TARGET = np.array([\n",
    "    [0, 0],\n",
    "    [TARGET_WIDTH - 1, 0],\n",
    "    [TARGET_WIDTH - 1, TARGET_HEIGHT - 1],\n",
    "    [0, TARGET_HEIGHT - 1],\n",
    "])\n",
    "\n",
    "class ViewTransformer:\n",
    "    def __init__(self, source: np.ndarray, target: np.ndarray) -> None:\n",
    "        source = source.astype(np.float32)\n",
    "        target = target.astype(np.float32)\n",
    "        self.m = cv2.getPerspectiveTransform(source, target)\n",
    "\n",
    "    def transform_points(self, points: np.ndarray) -> np.ndarray:\n",
    "        if points.size == 0:\n",
    "            return points\n",
    "        reshaped_points = points.reshape(-1, 1, 2).astype(np.float32)\n",
    "        transformed_points = cv2.perspectiveTransform(reshaped_points, self.m)\n",
    "        return transformed_points.reshape(-1, 2)\n",
    "\n",
    "def parse_arguments() -> argparse.Namespace:\n",
    "    parser = argparse.ArgumentParser(description=\"Vehicle Speed Estimation\")\n",
    "    parser.add_argument(\n",
    "        \"--source_video_path\",\n",
    "        default=r\"E:\\Study\\deeplearning\\final\\supervision\\examples\\speed_estimation\\data\\car.mp4\",\n",
    "        help=\"Path to source video\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--target_video_path\",\n",
    "        default=r\"E:\\Study\\deeplearning\\final\\supervision\\examples\\speed_estimation\\data\\output_speed_gpu.mp4\",\n",
    "        help=\"Path to output video\",\n",
    "        type=str,\n",
    "    )\n",
    "    # Tăng confidence lên 0.4 vì model Large rất tự tin, lọc bớt nhiễu\n",
    "    parser.add_argument(\"--confidence_threshold\", default=0.4, type=float)\n",
    "    parser.add_argument(\"--iou_threshold\", default=0.7, type=float)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✅ Đang sử dụng GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        print(\"⚠️ CẢNH BÁO: Đang chạy bằng CPU! Hãy cài lại PyTorch bản CUDA để tận dụng RTX 3050 Ti.\")\n",
    "        device = 'cpu'\n",
    "    \n",
    "\n",
    "    args = parse_arguments()\n",
    "\n",
    "    video_info = sv.VideoInfo.from_video_path(video_path=args.source_video_path)\n",
    "    \n",
    "    \n",
    "    print(\"Đang tải model YOLO11 Large...\")\n",
    "    model = YOLO(\"yolo11l.pt\") \n",
    "    model.to(device) # Đẩy model vào GPU\n",
    "\n",
    "    byte_track = sv.ByteTrack(\n",
    "        frame_rate=video_info.fps, \n",
    "        track_activation_threshold=args.confidence_threshold\n",
    "    )\n",
    "\n",
    "    thickness = sv.calculate_optimal_line_thickness(resolution_wh=video_info.resolution_wh)\n",
    "    text_scale = sv.calculate_optimal_text_scale(resolution_wh=video_info.resolution_wh)\n",
    "    \n",
    "    box_annotator = sv.BoxAnnotator(thickness=thickness)\n",
    "    label_annotator = sv.LabelAnnotator(\n",
    "        text_scale=text_scale,\n",
    "        text_thickness=thickness,\n",
    "        text_position=sv.Position.BOTTOM_CENTER,\n",
    "    )\n",
    "    trace_annotator = sv.TraceAnnotator(\n",
    "        thickness=thickness,\n",
    "        trace_length=video_info.fps * 2,\n",
    "        position=sv.Position.BOTTOM_CENTER,\n",
    "    )\n",
    "\n",
    "    frame_generator = sv.get_video_frames_generator(source_path=args.source_video_path)\n",
    "    polygon_zone = sv.PolygonZone(polygon=SOURCE)\n",
    "    view_transformer = ViewTransformer(source=SOURCE, target=TARGET)\n",
    "\n",
    "    coordinates = defaultdict(lambda: deque(maxlen=video_info.fps))\n",
    "\n",
    "    cv2.namedWindow(\"Speed Estimation GPU\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Speed Estimation GPU\", 1280, 720)\n",
    "\n",
    "    with sv.VideoSink(args.target_video_path, video_info) as sink:\n",
    "        for frame in frame_generator:\n",
    "            \n",
    "            # Chạy nhận diện \n",
    "            result = model(frame, verbose=False)[0]\n",
    "            detections = sv.Detections.from_ultralytics(result)\n",
    "\n",
    "            # Lọc xe cộ\n",
    "            detections = detections[np.isin(detections.class_id, [2, 3, 5, 7])]\n",
    "            detections = detections[detections.confidence > args.confidence_threshold]\n",
    "            detections = detections[polygon_zone.trigger(detections)]\n",
    "            detections = detections.with_nms(threshold=args.iou_threshold)\n",
    "            \n",
    "            detections = byte_track.update_with_detections(detections=detections)\n",
    "\n",
    "            points = detections.get_anchors_coordinates(anchor=sv.Position.BOTTOM_CENTER)\n",
    "            points = view_transformer.transform_points(points=points).astype(int)\n",
    "\n",
    "            for tracker_id, [_, y] in zip(detections.tracker_id, points):\n",
    "                coordinates[tracker_id].append(y)\n",
    "\n",
    "            labels = []\n",
    "            for tracker_id, class_id in zip(detections.tracker_id, detections.class_id):\n",
    "                class_name = model.names[class_id]\n",
    "                \n",
    "                if len(coordinates[tracker_id]) < video_info.fps / 2:\n",
    "                    labels.append(f\"#{tracker_id} {class_name}\")\n",
    "                else:\n",
    "                    coordinate_start = coordinates[tracker_id][-1]\n",
    "                    coordinate_end = coordinates[tracker_id][0]\n",
    "                    distance = abs(coordinate_start - coordinate_end)\n",
    "                    time = len(coordinates[tracker_id]) / video_info.fps\n",
    "                    speed = distance / time * 3.6\n",
    "                    labels.append(f\"#{tracker_id} {int(speed)} km/h\")\n",
    "\n",
    "            annotated_frame = frame.copy()\n",
    "            cv2.polylines(annotated_frame, [SOURCE.astype(np.int32)], True, (0, 0, 255), 2)\n",
    "            \n",
    "            annotated_frame = trace_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "            annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "            annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "            sink.write_frame(annotated_frame)\n",
    "            \n",
    "            display_frame = cv2.resize(annotated_frame, (1280, 720))\n",
    "            cv2.imshow(\"Speed Estimation GPU\", display_frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        \n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
